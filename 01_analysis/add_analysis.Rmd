---
title: "Supplemental Analyses"
author: "Jennah Gosciak"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  pdf_document:
    toc: true
    toc_depth: 2
    number_sections: false
---

```{r setup, set.seed(1690)}
```

```{r, include = F}
#options(warn=-1)
suppressPackageStartupMessages(library(tibble))
library(tidyverse)
library(knitr)
library(rgl)
library(rstan)
options(mc.cores = parallel::detectCores())
library(readr)
library(dplyr)
library(ggplot2)
library(purrr)
library(rstanarm)
library(loo)
library(bayesplot)
library(haven)

set.seed(1690)
```

This PDF uses the same data as [final_project.pdf](), but uses the Gamma distribution with a log link and a hierarchical model where intercepts vary by state.

```{r}
## load data
df <- read_dta("../00_data/sample1.dta")
df_samp <- df %>% 
  sample_n(3000)

df_samp <- df_samp %>% 
  mutate(across(c("age", "age_fbirth"), ~ . - mean(., na.rm = T))) %>% 
  mutate(l_incwage = if_else(incwage <= 0, log(1), log(incwage)),
         l_wkswork1 = if_else(wkswork1 <= 0, log(1), log(wkswork1)),
         incwage_mod = if_else(incwage <= 0, 1, incwage))

df_samp %>% 
  group_by(samesex) %>% 
  summarize(n = n())
```

# Analysis

## Model with Gamma distribution

* I explored using the gamma distribution with a log link function since the income data is right-skewed and positive.
* First, I tested out the program on a slightly larger sample using `rstanarm`.
* Then, I ran a smaller sample on a stan program I wrote myself, which is a simpler and slower version of the implementation in `rstanarm`. Because it takes so long to run, I only ran the model on 1,000 observations. The 95% credible intervals for the coefficients all contain 0 and consequently are not conclusive about any non-zero effect.

### Using `rstanarm` for the Gamma distribution with log link

```{r}
## running with rstanarm
post_gamma_rs <- stan_glm(incwage_mod ~ cnum_mt2 + age + age_fbirth + f_boy + 
                            s_boy + r_black + hisp + r_oth, data = df_samp,
                family = Gamma(link = "log"),
                prior_intercept = normal(10, 1),
                prior = normal(0, 1),
                seed = 12345)

post_gamma_rs

loo_gamma <- loo(post_gamma_rs)
loo_gamma

pp_check(post_gamma_rs,
  plotfun = "ppc_dens_overlay"
)
```
There are no Pareto k values > 0.5, which indicates that importance sampling was able to estimate the `elpd_loo` accurately. Additionally, `p_loo < p`, which doesn't indicate any potential issues with model misspecification. The `elpd_loo` is small. Comparing the `elpd_loo` will allow for comparisons.

The posterior predictive distribution does appear to be a less smooth version of the observed values of y. However, since the distribution is so skewed, it's difficult to visually inspect the overlap at the extreme ends of the distribution.

### Alternative approach using custom stan program
* The estimated coefficient values vary slightly from the above estimates generated by `rstanarm`. I include them for comparison.

```{r}
## make sample smaller for running with user written stan program
df_samp2 <- df %>% 
  sample_n(1000)

df_samp2 <- df_samp2 %>% 
  mutate(across(c("age", "age_fbirth"), ~ . - mean(., na.rm = T))) %>% 
  mutate(l_incwage = if_else(incwage <= 0, log(1), log(incwage)),
         l_wkswork1 = if_else(wkswork1 <= 0, log(1), log(wkswork1)),
         incwage_mod = if_else(incwage <= 0, 1, incwage))
```


```{r}
writeLines(readLines("linear_gamma.stan"))
```


```{r, cache = TRUE}
# use normal priors
m <- c(10, rep(-0.1, 8))
s<- rep(1, 9)

stan_data <- list(N = nrow(df_samp2), K = 8, 
                                        y = df_samp2$incwage_mod, 
                                        X = df_samp2[, c("cnum_mt2", "age", 
                                                        "age_fbirth", "f_boy", 
                                                   "s_boy", "r_black", 
                                                   "hisp", "r_oth")],
                                        prior_only = TRUE, m = m, 
                                        scale = s, r = 1)

pre_gamma <- stan("linear_gamma.stan", data = stan_data, seed = 12345)
```
```{r}
# print output
print(pre_gamma, pars = c("alpha", "beta", "shape"))
```

```{r}
hist(rstan::extract(pre_gamma, par = "yrep")$yrep,
     main = "Prior predictive distribution")
```

The prior predictive distribution generates large, extreme values of y. At the same time, most observations are clustered toward 0.

```{r, cache = TRUE}
# set prior to false, run the full dist
stan_data$prior_only <- FALSE
post_gamma <- stan("linear_gamma.stan", data = stan_data, seed = 12345)
```

```{r}
# print output
print(post_gamma, pars = c("alpha", "beta", "shape"))
```

The posterior distribution when using a log link and the gamma distribution is not conclusive about the effect of additional children on earnings. The coefficient on `cnum_mt2` is on average 0 and the 95% credible interval is between -0.01 and 0.01. Almost all the predictors ahve values close to 0. The small values for the coefficients, as indicated by the marginal distributions, is likely due to the conversion from log earnings to earnings in dollars.


```{r}
pairs(post_gamma, pars = c("alpha", "beta", "shape"))
```

The marginal distribution of the parameters all seem approximately normal, even for shape. 

```{r}
pp_check(as.numeric(stan_data$y),
  rstan::extract(post_gamma, par = "yrep")$yrep[sample(1:length(stan_data$y), size = 150), ],
  ppc_dens_overlay
)
```

The posterior predictive distribution does appear to closely follow the observed values of y, which are less smooth. However, it's difficult to tell in the tails if the observed values and the predicted values diverge.

```{r}
# comparison of predictions
yrep <- rstan::extract(post_gamma, "yrep")[[1]]
low  <- apply(yrep, MARGIN = 2, FUN = quantile, probs = 1 / 3)
high <- apply(yrep, MARGIN = 2, FUN = quantile, probs = 2 / 3)
```

```{r}
y <- stan_data$y

c(too_low = mean(y < low), 
  just_right = mean(y > low & y < high),
  too_high = mean(y > high))
```

The model is predicting too many extreme values (bottom and top third percentiles). Only 8% of observed y-values fall in only the middle third percentile.

```{r}
loo_gamma2 <- loo(post_gamma)
loo_gamma2
```

All the Pareto k values are less than 0.5, which indicates that importance sampling can generate a good estimate. However, `p_loo << p`, which might be evidence that the model is misspecified.

## Hierarchical linear model

* Allowing intercepts to shift based on state
* Replicates the linear model and the IV model

```{r, cache = TRUE}
# set generic priors
m <- rep(0, 9)
s<- rep(1, 9)

# set states as ordered factor
states <- as.integer(as.factor(df_samp$statefip))


stan_data <- list(N = nrow(df_samp), K = 8, J = 51,
                                        states = states,
                                        y = df_samp$l_incwage, 
                                        # use fewer predictors
                                        X = df_samp[, c("cnum_mt2", "age", 
                                                        "age_fbirth", "f_boy",
                                                        "s_boy",
                                                        "r_black", "hisp", 
                                                        "r_oth")],
                                        prior_only = FALSE, m = m, 
                                        scale = s, r = 1)

post_mlm <- stan("linear_mlm.stan", data = stan_data, seed = 1234)
```
```{r}
print(post_mlm, pars = c("alpha", "beta"))
```

When the alpha values vary, the coefficient on `cnum_mt2` is inconclusive. The 95% credible interval is from -0.54 to 0.15 and the mean is -0.19. Considering that the outcome is in log units, this indicates a broad range of effects and a high level of uncertainty about the impact of any one covariate.


```{r}
loo_mlm <- loo(post_mlm)
loo_mlm
```

All Pareto k estimates are less than 0.5, which indicates that importance sampling is able to estimate the `elpd_loo` accurately and there are few observed values that have an outsized influence. The `elpd_loo` will be useful for comparing to other models.

```{r}
## visualize density
pp_check(as.numeric(stan_data$y),
  rstan::extract(post_mlm, par = "yrep")$yrep[sample(1:length(stan_data$y), size = 150), ],
  ppc_dens_overlay
)

# comparison of predictions
yrep <- rstan::extract(post_mlm, "yrep")[[1]]
low  <- apply(yrep, MARGIN = 2, FUN = quantile, probs = 1 / 3)
high <- apply(yrep, MARGIN = 2, FUN = quantile, probs = 2 / 3)

y <- stan_data$y

c(too_low = mean(y < low), 
  just_right = mean(y > low & y < high),
  too_high = mean(y > high))
```

Since the observed values of y appear to be bimodal, the posterior predictive distribution, which is approximately normal, has trouble predicting values at both ends. 

The model is predicting too many extreme values (in the bottom and top tertile). In terms of prediction, it is slightly better than the previous model with the gamma distribution and a log link. Almost 6% of observed y values fall within the middle tertile.

## Hierarchical IV model

```{r}
# set generic priors
m <- rep(0, 9)
s<- rep(1, 9)

# set states as ordered factor
df_samp$states <- as.integer(as.factor(df_samp$statefip))

# subset the data
df_child <- df_samp %>% 
  filter(cnum_mt2 == 1)

df_nochild <- df_samp %>% 
  filter(cnum_mt2 == 0)
```

```{r, cache = TRUE}
# reset covariates, use only 4 covariates
cov <- c("age", "age_fbirth", "f_boy", "s_boy", "r_black", "hisp", "r_oth")

# set stan data
stan_data_iv <- list(N = nrow(df_samp),
                  N_child = nrow(df_child),
                  N_nochild = nrow(df_nochild),
                  K = 7,
                  J = 51,
                  states_child = df_child$states,
                  states_nochild = df_nochild$states,
                  X_child_s = df_child[, c("samesex", cov)],
                  X_nochild_s = df_nochild[, c("samesex", cov)],
                  X_child = df_child[, c(cov)],
                  X_nochild = df_nochild[, c(cov)],
                  y_child = df_child$l_incwage,
                  y_nochild = df_nochild$l_incwage,
                  prior_only = FALSE,
                  m = rep(-0.1, 5), 
                  scale = rep(0.3, 5))

post_iv_mlm <- stan("iv_bin_mlm.stan",
                 data = stan_data_iv, seed = 1234)
```

```{r}
print(post_iv_mlm, pars = c("beta1", "beta2", "alpha0", "alpha1"))
```

Based on the value of `beta2`, the output indicates that the impact of `cnum_mt2` is likely positive when including an instrument to isolate the causal effect and allowing variation in intercepts. The average estimated value of `beta2` is 4.13 and the 95% credible interval is from 3.74 to 4.52. Similar to the non-hierarchical models, there may be some limitations to the interpretation of a true effect from this model:

1. it only uses 3,000 observations from the full sample
2. it does not account for the fact that income is conditional on labor force participation
3. the model does not have good predictive capabilities compared to the simpler model


```{r}
loo_iv_mlm <- loo(post_iv_mlm)
loo_iv_mlm

loo_compare(loo_iv_mlm, loo_mlm, loo_gamma)
```

The simpler linear model appears to be the better model in terms of prediction accuracy based on cross-validation. The `elpd_diff` values is much larger than the SE.

```{r}
# visualize density
pp_check(c(as.numeric(stan_data_iv$y_child),
           as.numeric(stan_data_iv$y_nochild)),
  rstan::extract(post_iv_mlm, par = "yrep")$yrep[sample(1:nrow(df_samp),
                                                    size = 150), ],
  ppc_dens_overlay
)

# comparison of predictions
yrep <- rstan::extract(post_mlm, "yrep")[[1]]
low  <- apply(yrep, MARGIN = 2, FUN = quantile, probs = 1 / 3)
high <- apply(yrep, MARGIN = 2, FUN = quantile, probs = 2 / 3)

y <- stan_data$y

c(too_low = mean(y < low), 
  just_right = mean(y > low & y < high),
  too_high = mean(y > high))
```

As with the other linear model, the approximately normal posterior predictive distribution does not fully align with the bimodal distribution of observed y values. 

## Conclusion






